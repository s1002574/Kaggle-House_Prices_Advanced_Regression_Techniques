{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# gc.collect()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from my_toolbox import create_model as cm\n",
    "from my_toolbox import data_describe as dd\n",
    "from my_toolbox import stepwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 196)\n",
      "(1459, 195)\n",
      "(1459, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "duplicate       0.0\n",
       "is_null         0.0\n",
       "null_number     0.0\n",
       "null_rate(%)    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/'\n",
    "data_name = [\"df_train\", 'df_test', 'sample_submission']\n",
    "\n",
    "df_train_all = pd.read_csv(\"{}{}.csv\".format(path,data_name[0]), encoding='utf8')\n",
    "print(df_train_all.shape)\n",
    "\n",
    "df_test = pd.read_csv(\"{}{}.csv\".format(path,data_name[1]), encoding='utf8')\n",
    "print(df_test.shape)\n",
    "\n",
    "df_submit = pd.read_csv(\"{}{}.csv\".format(path,data_name[2]), encoding='utf8')\n",
    "print(df_submit.shape)\n",
    "\n",
    "# -----------data info\n",
    "data_describe1 =dd.data_describe(df_train_all);\n",
    "data_describe2 = dd.data_describe(df_test);\n",
    "data_describe1[data_describe1.is_null==True].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RoofMatl_WdShake', 'Neighborhood_Blmngtn', 'RoofMatl_WdShngl',\n",
      "       'Neighborhood_NridgHt', 'PCA_7', 'Neighborhood_CollgCr',\n",
      "       'Condition1_PosN', 'Condition2_Artery', 'GarageFinish',\n",
      "       'Exterior2nd_CBlock',\n",
      "       ...\n",
      "       'Foundation_Stone', 'SaleType_New', 'LowQualFinSF', 'MSSubClass_80',\n",
      "       'MoSold_12', 'Neighborhood_NAmes', 'SaleType_Con', 'BldgType_1Fam',\n",
      "       'Neighborhood_Crawfor', 'SalePrice'],\n",
      "      dtype='object', length=196)\n",
      "Index(['RoofMatl_WdShake', 'Neighborhood_Blmngtn', 'RoofMatl_WdShngl',\n",
      "       'Neighborhood_NridgHt', 'PCA_7', 'Neighborhood_CollgCr',\n",
      "       'Condition1_PosN', 'Condition2_Artery', 'GarageFinish',\n",
      "       'Exterior2nd_CBlock',\n",
      "       ...\n",
      "       'Exterior2nd_CmentBd', 'Foundation_Stone', 'SaleType_New',\n",
      "       'LowQualFinSF', 'MSSubClass_80', 'MoSold_12', 'Neighborhood_NAmes',\n",
      "       'SaleType_Con', 'BldgType_1Fam', 'Neighborhood_Crawfor'],\n",
      "      dtype='object', length=195)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_all.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Select \n",
    "## By Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "x = df_train_all.iloc[:, :-1].values\n",
    "y = df_train_all.iloc[:, -1]\n",
    "\n",
    "# lassocv = LassoCV(alphas=[i for i in range(1, 1000)], max_iter=50000, normalize=False)\n",
    "lassocv = LassoCV(max_iter=500000, normalize=True)\n",
    "lassocv.fit(x, y)\n",
    "\n",
    "mask = (lassocv.coef_ != 0)\n",
    "print(mask.sum())\n",
    "x = x[:, mask]\n",
    "print(x.shape)\n",
    "print(lassocv.alpha_)\n",
    "\n",
    "df_test = df_test.loc[:, mask]\n",
    "print(type(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Stepwise"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('MSZoning_C' in list(df_train_all.columns))\n",
    "\n",
    "df_train_all.rename(index=str, columns={\"MSZoning_C (all)\": \"MSZoning_C\"}, inplace=True)\n",
    "print('MSZoning_C' in list(df_train_all.columns))\n",
    "\n",
    "list(df_train_all.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = stepwise.forward_selected(df_train_all, 'SalePrice')\n",
    "\n",
    "print(model.params.count())\n",
    "print(model.rsquared_adj)\n",
    "mask = list(model.params.index)\n",
    "mask.remove('Intercept')\n",
    "print(len(mask))\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Train data's x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x = x\n",
    "df_train_y = y\n",
    "# df_train_x = df_train_all.iloc[:, :-1].values\n",
    "# df_train_y = df_train_all.iloc[:, -1].values\n",
    "print(df_train_x.shape)\n",
    "print(df_train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df_train_x = df_train_x.values\n",
    "# df_train_y = df_train_y.values\n",
    "train_x, val_x, train_y, val_y = train_test_split(df_train_x, df_train_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = cm.modeling(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "linear = my_model.linear_modeling(to_normalize=True)\n",
    "pred_y = linear.predict(df_test)\n",
    "# print(linear.coef_)\n",
    "# print(linear.intercept_)\n",
    "\n",
    "df_result = pd.DataFrame(df_submit['Id'])\n",
    "df_result['SalePrice'] = pred_y\n",
    "df_result.to_csv('../submit/LR_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "\n",
    "lassocv = LassoCV(eps=0.001, \n",
    "                  n_alphas=100, \n",
    "                  alphas=[0.01, 0.1, 0, 1, 5, 10, 100, 1000], \n",
    "                  fit_intercept=True, \n",
    "                  normalize=True, \n",
    "                  precompute='auto', \n",
    "                  max_iter=100000, \n",
    "                  tol=0.000001, \n",
    "                  copy_X=True, \n",
    "                  cv='warn', \n",
    "                  verbose=False, \n",
    "                  n_jobs=-1, \n",
    "                  positive=False, \n",
    "                  random_state=None, \n",
    "                  selection='cyclic')\n",
    "\n",
    "lassocv.fit(train_x, train_y)\n",
    "alpha = lassocv.alpha_\n",
    "print('alpha=', alpha)\n",
    "max_iter = lassocv.max_iter\n",
    "tol = lassocv.tol\n",
    "\n",
    "# use to do feayure select\n",
    "mask = (lassocv.coef_ != 0)\n",
    "features = list(train_x.loc[:,mask].columns)\n",
    "print('Feature select:\\n', features)\n",
    "print('Features number', len(features))\n",
    "\n",
    "\n",
    "\n",
    "lasso_regressor = Lasso(max_iter=max_iter, alpha=alpha, tol=tol)\n",
    "lasso_model = lasso_regressor.fit(train_x, train_y)\n",
    "pred_y = lasso_model.predict(val_x)\n",
    "print('r2_score = ', r2_score(val_y, pred_y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# the module we have write\n",
    "lasso = my_model.lasso_moedeling()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output result to csv\n",
    "pred_y = lasso_model.predict(df_test)\n",
    "df_result = pd.DataFrame(df_submit['Id'])\n",
    "df_result['SalePrice'] = pred_y\n",
    "df_result.to_csv('../submit/Lasso_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "\n",
    "ridgecv = RidgeCV(alphas=(0.1, 1.0, 10.0), \n",
    "                fit_intercept=True, \n",
    "                normalize=True,\n",
    "                scoring=None,\n",
    "                cv=10,\n",
    "                gcv_mode=None,\n",
    "                store_cv_values=False)\n",
    "\n",
    "ridgecv.fit(train_x, train_y)\n",
    "alpha = ridgecv.alpha_\n",
    "\n",
    "ridge_regression = Ridge(alpha=alpha,\n",
    "                         fit_intercept=True,\n",
    "                         normalize=True,\n",
    "                         copy_X=True,\n",
    "                         max_iter=10000000,\n",
    "                         tol=0.0000001,\n",
    "                         solver='auto',\n",
    "                         random_state=None)\n",
    "ridge_model = ridge_regression.fit(train_x, train_y)\n",
    "\n",
    "pred_y = ridge_model.predict(val_x)\n",
    "print('r2_score= ', r2_score(val_y, pred_y))\n",
    "\n",
    "# print(ridge_model.coef_)\n",
    "# print(ridge_model.intercept_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# the module we have write\n",
    "ridge_model = my_model.ridge_modeling(max_iterater=100000000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output result to csv\n",
    "pred_y = ridge_model.predict(df_test)\n",
    "df_result = pd.DataFrame(df_submit['Id'])\n",
    "df_result['SalePrice'] = pred_y\n",
    "df_result.to_csv('../submit/Ridge_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "elasticnetcv = ElasticNetCV(l1_ratio=0.5,\n",
    "                         eps=0.0001,\n",
    "                         n_alphas=1000,\n",
    "                         alphas=None,\n",
    "                         fit_intercept=True,\n",
    "                         normalize=True,\n",
    "                         precompute='auto',\n",
    "                         max_iter=100000,\n",
    "                         tol=0.00001,\n",
    "                         cv='warn',\n",
    "                         copy_X=True,\n",
    "                         verbose=0,\n",
    "                         n_jobs=-1,\n",
    "                         positive=False,\n",
    "                         random_state=None,\n",
    "                         selection='cyclic')\n",
    "\n",
    "elasticnetcv.fit(train_x, train_y)\n",
    "tol = elasticnetcv.tol\n",
    "l1_ratio = elasticnetcv.l1_ratio\n",
    "\n",
    "elasticnet_regressor = ElasticNet(max_iter = 1000000, l1_ratio = l1_ratio, tol=tol)\n",
    "elasticnet_model = elasticnet_regressor.fit(train_x, train_y)\n",
    "pred_y = elasticnet_model.predict(val_x)\n",
    "print('r2_score = ', r2_score(val_y, pred_y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# the module we have write\n",
    "elasticnet_model = my_model.elastic_modeling()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output result to csv\n",
    "pred_y = elasticnet_model.predict(df_test)\n",
    "df_result = pd.DataFrame(df_submit['Id'])\n",
    "df_result['SalePrice'] = pred_y\n",
    "df_result.to_csv('../submit/Elasticnet_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = { \n",
    "            'bootstrap': [True],\n",
    "            'max_depth': [80, 90, 100, 110],\n",
    "            'max_features': [2, 3],\n",
    "            'min_samples_leaf': [3, 4, 5],\n",
    "            'min_samples_split': [8, 10, 12],\n",
    "            'n_estimators': [100, 200, 300, 1000]\n",
    "        }\n",
    "# [i/10000 for i in range(1000, 5000, 1)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "grid_rf = GridSearchCV(rf, param_grid, n_jobs=-1, cv=5)\n",
    "forest_model = grid_rf.fit(train_x, train_y)\n",
    "\n",
    "pred_y = forest_model.predict(val_x)\n",
    "\n",
    "print('Root Mean Square Error = ',\n",
    "      str(math.sqrt(mean_squared_error(val_y, pred_y))))\n",
    "print('r2_score = ', r2_score(val_y, pred_y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# the module we have write\n",
    "rf_model = my_model.rf_modeling(param_grid, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output result to csv\n",
    "pred_y = rf_model.predict(df_test)\n",
    "df_result = pd.DataFrame(df_submit['Id'])\n",
    "df_result['SalePrice'] = pred_y\n",
    "df_result.to_csv('../submit/rf_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#給予模型參數，告知演算法該如何訓練模型\n",
    "param = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective':'reg:linear', # 做線性回歸\n",
    "        'tree_method':'hist',\n",
    "        'gamma':0.1,    # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "        'silent':1,     # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "        'subsample': 0.8,  # 随机采样训练样本\n",
    "        'max_depth':5,     # 构建树的深度，越大越容易过拟合\n",
    "        'nthread': 8,      # cpu 线程数\n",
    "        'lambda': 15,       # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "        'eta': 0.08,                  # 如同学习率\n",
    "        'seed': 10000,\n",
    "        'min_child_weight': 3\n",
    "        }\n",
    "num_round = 200\n",
    "\n",
    "\n",
    "xgb_model = my_model.xgb_modeling(param, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output result to csv\n",
    "import xgboost as xgb\n",
    "\n",
    "test_x = df_test.values\n",
    "\n",
    "xgb_test_x = xgb.DMatrix(test_x)\n",
    "\n",
    "test_y = xgb_model.predict(xgb_test_x)\n",
    "\n",
    "\n",
    "df_result = pd.DataFrame(df_submit['Id'])\n",
    "df_result['SalePrice'] = test_y\n",
    "df_result.to_csv('../submit/xgb_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
